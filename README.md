# MovieDB

MovieDB is a website for browsing through a wide variety of movies. Current features include:

- A feed of movies
- Detailed movie information pages
- Search for movie titles
- Sorting and filtering with various options
- Changing users by updating your username
- Adding reviews for movies
- A feed of the latest reviews from all users
- A list of your own reviews

![Main page](https://i.imgur.com/1e2EkeQ.jpg)

## Usage

### Running the frontend locally

The following commands can be run in the `T26-Project-2/frontend` directory:

- `npm install` to install dependencies.
- `npm run dev` to start the development server
- `npm run prettier` to check code formatting
  - `npm run prettier:fix` to fix formatting
- `npm run lint` to check for linting errors
  - `npm run lint:fix` to fix auto fixable linting errors
- `npm test` to run all frontend tests
  - `npm run coverage` to generate a test coverage report at `frontend/coverage/index.html`
- `npm run build` to build the project
  - it will be built in the `dist` folder

### Restarting the frontend on the VM

Navigate to the `~/T26-Project-2/frontend` directory

- `npm ci` to install dependencies (and stop on mismatches between the `package[-lock].json` files)
- `npm run build` to build the project
- `../reload_server_frontend` to update the apache server

### Running the backend locally

The following commands can be run in the `T26-Project-2/backend` directory:

- `npm install` to install dependencies.
- `npm run prettier` to check code formatting
  - `npm run prettier:fix` to fix formatting
- `npm run lint` to check for linting errors
  - `npm run lint:fix` to fix auto fixable linting errors
- `npm test` to run all backend tests
  - `npm run coverage` to generate a test coverage report at `backend/coverage/index.html`
- `npm run build` to build the project
- `npm run start` to start the server

### Running the backend on the VM

Navigate to the `~/T26-Project-2/backend` directory

- `npm install pm2 -g` to install pm2 globally
- `npm ci` to install dependencies (and stop on mismatches between the `package[-lock].json` files)
- `npm run build` to build the project
- `pm2 start dist/index.js` to start the server in the background
  - `pm2 logs` to see the logs
  - `pm2 list` to see the status of the process
  - `pm2 restart <id>` to restart the process (use the id from `pm2 list`)
  - `pm2 stop <id>` to stop the process (use the id from `pm2 list`)

### Running E2E tests

There is no need to fill a testing database manually, or even download MongoDB. The E2E tests (and the backend tests) use an in memory MongoDB server, which is automatically started, filled, reset and stopped when the tests are run. The following commands are the only commands needed to run the E2E tests.

In `T26-Project-2/backend`:

- `npm run build` to build the backend
- `npm run e2e:server` to start the test server

In `T26-Project-2/frontend`:

- `npm run dev` to start the development server
- One of the following commands:
  - `npm run e2e` to run the e2e tests (will run headlessly)
  - `npm run cy:open` to use the cypress app (provides visualization)

### Setting up the database / backend for the first time

#### NB: This is already done, so you don't need to do this

```bash
cd ~/T26-Project-2

# Download the dataset
curl -L -o archive.zip https://www.kaggle.com/api/v1/datasets/download/asaniczka/tmdb-movies-dataset-2023-930k-movies
sudo apt-get install unzip
unzip archive.zip
rm archive.zip
mv TMDB_movie_dataset_v11.csv TMDB_movie_dataset.csv

# Parse the data and insert it into the database
pip install pandas pymongo tqdm
./parse_data.py db 0

# Start the backend
cd backend/
npm ci
npm run build
pm2 start dist/index.js
```

## Choices

### Frontend

We've used UI components from `shadcn`, as it allows us to copy and paste components directly into our project. This gives us more flexibility and control over the components and provides the opportunity to, for example, adjust styling to meet our needs. It also allows us to include only the components we need, resulting in a smaller bundle size and faster load times.

We use `Tailwind CSS`, instead of traditional CSS, because we believe it makes us develop code more efficiently, and it allows us to write less code to achieve the same result.

We use `Apollo Client` for managing global state across all components and for creating GraphQL queries to the backend. It also provides caching of our queries to improve the performance of the application. For GraphQL queries and types, we use `GraphQL Codegen` to generate the types automatically based on the schemas provided by the backend. This makes our queries type-safe in the frontend and we only need to define the types in one place (the types are generated by running `npm run generate`).

LocalStorage is used to remember the username of the logged in user, so that the user is remembered even when you close the browser. SessionStorage on the other hand is used to remember filters, sorting option and search during a session.

### Backend

For the backend, we use `Apollo Server` with `MongoDB` as our database. We believe that `MongoDB` works well in combination with GraphQL because it allows us to store data in a similar format to the GraphQL types. This minimizes the work required for processing data before inserting it into the database and after retrieving data from the database.

Our sorting, filtering and search logic is in the backend so that we can use the whole dataset. Here we use indexes in order to improve performance. While we initially used a text index for titles, we later opted for regex search to allow for partial match. We found that this led to a much better user experience, with minimal impact on performance.

We initially had over 700.000 movies in our database, but we later found that most movies were inappropriate or just joke entries. Therefore, we decided to remove many movies based on some criteria. If certain fields are null for example, it doesn't make sense to have the entries: title, release_date, overview, and runtime all have to have a value. Other criteria get rid of a lot of the inappropriate movies: adult = false, imdb_id != null. Then, we only kept the top 10.000 most popular movies. This ensures that we have as many known movies as possible while avoiding most of the inappropriate/irrelevant movies that haven't been filtered out already.

### Testing

#### Component tests

For our frontend components, we've set up tests using `vitest` to make sure each component works as expected. We've focused on testing the specific functionality of each component, keeping things isolated by using mocking. This includes mocking API responses, functions, and even other components when needed. This way, we can test components without worrying about external dependencies and ensure they handle different scenarios properly.

#### Snapshot tests

We have snapshot tests for many of our frontend components and pages. We also have snapshot tests in the backend, to ensure that the results of large queries stay consistent. For our snapshot tests in the frontend, we have decided to mock as many of the underlying child components as possible. This makes it easier for us to detect where snapshot discrepancies originate, as a mistake in one component won't make all snapshot tests fail, but only the relevant one.

#### API tests

For the backend, we've written tests using `vitest`. To not pollute our production database every time we test, and to simplify integration into our CI pipeline, we use `mongodb-memory-server` as the database for these tests. This allows us to run tests in an isolated and consistent environment. It also allows anyone to run our tests, without downloading MongoDB and filling it with data first.

Our tests cover each resolver and utility function in isolation, ensuring the backend behaves as expected. We also test each resolver with actual HTTP requests, and for these complex results, we rely on snapshots to verify that the output remains consistent across runs. This approach helps us maintain accuracy and reliability throughout our testing process.

#### End-to-end tests

We have made end-to-end tests using `Cypress`, as it's known to work well for e2e testing of web applications. When running the end-to-end tests we use `mongodb-memory-server`, as with the API tests, for the same reasons mentioned earlier. For the tests we have sequences of actions with varying length and complexity that imitate real user behavior. We've tried to be thorough, covering edge cases we know can be sources to issues. As an example, we test that reviews are updated correctly in the cache by submitting/deleting a review, then visiting the Activity page and My Reviews page, before returning to the initial movie. For search, sorting and filtering, we've already tested the API responses in the backend tests. Therefore, we focused mainly on checking that requests had the correct variables and that the response data was rendered correctly. Still, we test that search, sorting, filtering and paging work well together through several different action sequences. Due to variations in loading time as a result of for example network congestion, there is a small possibility that tests can fail. However, as we use wait() to handle this problem, this is a rare occurrence. Still, it's worth a mention.

**Note**: There are some warnings that appear when running the E2E tests. These come from code Cypress itself references, so we are not able to fix these issues ourselves.

### Accessibility

We've put a lot of effort into making sure our application is accessible for everyone. Accessibility is a core part of what makes a good user experience, so here are some of the steps we've taken to make our app more inclusive:

- **Semantic HTML (WCAG 1.3.1)**: We use the right HTML tags to ensure that screen readers can easily interpret and present the content to users who rely on them. The few places `<div>`-tags have been used, this has been a deliberate choice, as no other element carried the appropriate semantic meaning.
- **ARIA Attributes (WCAG 4.1.2)**: We've added `aria-label` to give elements clear, descriptive names and used `aria-role` to specify roles when they're not obvious from the element type.
- **Image Descriptions (WCAG 1.1.1)**: All images come with `alt` text. This way, if an image doesn't load for any reason, the description still provides the necessary context for what was supposed to be there.
- **Keyboard Navigation (WCAG 2.1.1/2.1.2)**: The whole app is built to be navigable using only a keyboard, which is how some users prefer or need to interact with websites.
- **Color Contrast (WCAG 1.4.3)**: We've checked that all text and interactive elements have enough contrast with their backgrounds to be easily readable, especially for users with visual impairments.

To catch any accessibility issues, we've been using `Google Lighthouse`, a built-in browser tool, to analyze accessibility as well as performance, best practices, and Search Engine Optimization (SEO). Here's an example of a Lighthouse report for the homepage's initial load:

![Lighthouse report](docs/image.png)

_Note: This test was run with the backend on a local server, so the performance results might not be fully accurate._

#### WCAG

We have also manually tested the accessibility of the application using the WCAG-guidelines. Some of the most noteable changes we made based on WCAG were:

- Added a "Skip to Main Content" button to let users easily bypass the navbar when using a keyboard (WCAG 2.4.1).
- Give information to the user that adding filters, changing the sorting order or typing in the searchbar will automatically update the page (WCAG 3.2.2).
- Added a label explaining that picking a rating is mandatory when submitting a review, but adding a comment is optional (WCAG 3.3.2).

### Sustainability

During development, we've made sure to find sustainable solutions. The previous part about accessibility is already an important point, directly relating to the UN's Sustainable Development Goal 10, particularly 10.2, which focuses on inclusion of all, irrespective of for example disability. By focusing on accessible design we ensure greater inclusivity. However, as this topic also covers much more, we discuss some of the other ways we've ensured sustainability below.

#### Optimizing queries

- **Caching**: We use caching in order to reduce the number of queries to the backend and improve performance. This way we avoid fetching the same data multiple times, making the application more sustainable. When it comes to the caching of reviews, we had to find a balance between having up-to-date data and minimizing the number of queries. We found that the best solution was to have the user refresh in order to be sure of having the latest updates. This allows us to update the cache manually when adding/deleting a review, reducing the number of queries considerably while still feeling intuitive for the user.

- **Input validation in frontend**: For example, when changing username, we validate the new username before sending a call to the backend. We've put effort into having a robust API with appropriate error handling, meaning such an invalid username would be handled, but by having extra validation in the frontend we avoid the unnecessary call to the backend for a username we know is invalid.

- **Debounce**: In order to further reduce the query count, while still maintaining a good user experience, we decided to implement debounce on our search field. The delay is set to 510ms, as this gave a good balance between responsiveness and avoiding unnecessary queries. When holding down a key on the keyboard, the browser also waits 500ms to add more of the same character. Therefore, having a longer delay than this helps avoid an extra query when holding down a key.

- **Pagination**: To effectively handle a large dataset and avoid fetching unnecessary data, we implemented pagination. We fetch 20 movies/reviews at a time, as we found this to be an appropriate amount, taking both user experience and sustainability into consideration. By only fetching smaller, more manageable chunks of data we reduce data transfer and carbon cost.

- **GraphQL Usage**: Using GraphQL allows us to only fetch the specific data needed for the application, reducing unnecessary data transfer. This contrasts with traditional REST APIs, where one might end up fetching more data than needed or encounter issues like the N+1 query problem.

#### Media Handling

- **Reducing image sizes**: For components with smaller images, like `MovieCard.tsx` or `ReviewCard.tsx`, we realized that the default image sizes were way bigger than needed. Therefore, in order to reduce network traffic, we decided to request images of a smaller, more appropriate, size (`w342`). This makes for a more sustainable solution, consuming less bandwidth and energy during transmission.

- **WebP format**: In order to handle movies that didn't have a poster, we decided to provide a default poster. Here we made sure to use WebP image format, in addition to not making it bigger than necessary. For the other movie posters, we rely on a third-party API and were unfortunately not able to obtain them in the WebP format.

- **Videos and animations**: We chose to avoid videos and animations due their significant environmental impact. Videos and animations are particularly problematic, as they generate high data traffic and require considerable energy on the client device. If the user is interested in watching the trailer, they can instead visit the movie home page, which we link to.

#### Code Reusability

- **Minimizing redundancy**: During development we've made sure to make reusable components, while also gathering utility functions in the `utils` folder. This way we avoid code duplication and redundancy, making the code base more maintainable and fit for further development. This also reduces the application's overall size, decreasing the amount of data transferred to users, which in turn lowers energy consumption.
